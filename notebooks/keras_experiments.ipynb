{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2674 images belonging to 5 classes.\n",
      "Found 665 images belonging to 5 classes.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.16245, saving model to exp5-1_resnet_ckp_0.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.16245 to 1.20179, saving model to exp5-1_resnet_ckp_0.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.20179 to 1.15036, saving model to exp5-1_resnet_ckp_0.hdf5\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      "\n",
      "Epoch 00015: val_loss did not improve\n",
      "\n",
      "Epoch 00016: val_loss did not improve\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      "\n",
      "Epoch 00019: val_loss did not improve\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n",
      "\n",
      "Epoch 00021: val_loss did not improve\n",
      "\n",
      "Epoch 00022: val_loss did not improve\n",
      "\n",
      "Epoch 00023: val_loss did not improve\n",
      "\n",
      "Epoch 00024: val_loss did not improve\n",
      "\n",
      "Epoch 00025: val_loss did not improve\n",
      "\n",
      "Epoch 00026: val_loss did not improve\n",
      "\n",
      "Epoch 00027: val_loss did not improve\n",
      "\n",
      "Epoch 00028: val_loss did not improve\n",
      "\n",
      "Epoch 00029: val_loss did not improve\n",
      "\n",
      "Epoch 00030: val_loss did not improve\n",
      "\n",
      "Epoch 00031: val_loss did not improve\n",
      "\n",
      "Epoch 00032: val_loss did not improve\n",
      "\n",
      "Epoch 00033: val_loss did not improve\n",
      "\n",
      "Epoch 00034: val_loss did not improve\n",
      "\n",
      "Epoch 00035: val_loss did not improve\n",
      "\n",
      "Epoch 00036: val_loss did not improve\n",
      "\n",
      "Epoch 00037: val_loss did not improve\n",
      "\n",
      "Epoch 00038: val_loss did not improve\n",
      "\n",
      "Epoch 00039: val_loss did not improve\n",
      "\n",
      "Epoch 00040: val_loss did not improve\n",
      "\n",
      "Epoch 00041: val_loss did not improve\n",
      "\n",
      "Epoch 00042: val_loss did not improve\n",
      "\n",
      "Epoch 00043: val_loss did not improve\n",
      "\n",
      "Epoch 00044: val_loss did not improve\n",
      "\n",
      "Epoch 00045: val_loss did not improve\n",
      "\n",
      "Epoch 00046: val_loss did not improve\n",
      "\n",
      "Epoch 00047: val_loss did not improve\n",
      "\n",
      "Epoch 00048: val_loss did not improve\n",
      "\n",
      "Epoch 00049: val_loss did not improve\n",
      "\n",
      "Epoch 00050: val_loss did not improve\n",
      "665/665 [==============================] - 24s 36ms/step\n",
      "[[537   0   0   0   0]\n",
      " [ 29   0   0   0   0]\n",
      " [ 30   0   0   0   0]\n",
      " [ 48   0   0   0   0]\n",
      " [ 21   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from keras.applications import nasnet, resnet50, inception_v3\n",
    "from keras.preprocessing import image\n",
    "from keras import losses, metrics, callbacks, optimizers, activations, models, layers\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('tf')\n",
    "\n",
    "def _nasnet(num_classes, pretrained=True, freezed=True):\n",
    "    weights = 'imagenet' if pretrained else None\n",
    "    base_model = nasnet.NASNetMobile(weights=weights, include_top=False)\n",
    "    x = base_model.output\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    predictions = layers.Dense(num_classes, activation=activations.softmax, name='predictions')(x)\n",
    "    if freezed:\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = False\n",
    "    model = models.Model(inputs=base_model.input, outputs=predictions)\n",
    "    return model\n",
    "\n",
    "def _inception(num_classes, pretrained=True, freezed=True):\n",
    "    weights = 'imagenet' if pretrained else None\n",
    "    base_model = inception_v3.InceptionV3(weights=weights, include_top=False)\n",
    "    x = base_model.output\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(1024, activation=activations.relu)(x)\n",
    "    predictions = layers.Dense(num_classes, activation=activations.softmax, name='predictions')(x)\n",
    "    if freezed:\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = False\n",
    "    model = models.Model(inputs=base_model.input, outputs=predictions)\n",
    "    return model\n",
    "\n",
    "def _resnet(num_classes, pretrained=True, freezed=True):\n",
    "    weights = 'imagenet' if pretrained else None\n",
    "    base_model = resnet50.ResNet50(input_shape=(224,224,3), weights=weights, include_top=False)\n",
    "    x = base_model.output\n",
    "    x = layers.Flatten()(x)\n",
    "    predictions = layers.Dense(num_classes, activation=activations.softmax, name='predictions')(x)\n",
    "    if freezed:\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = False\n",
    "    model = models.Model(inputs=base_model.input, outputs=predictions)\n",
    "    return model\n",
    "\n",
    "\n",
    "dataset_path = '/home/daniel/Downloads/CBMS/exp5-1'\n",
    "\n",
    "for i in range(1):\n",
    "    img_size = 224\n",
    "    batch_size = 32\n",
    "    generator = image.ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "    #                                     ,shear_range=0.2,\n",
    "    #                                     zoom_range=0.2,\n",
    "    #                                     horizontal_flip=True)\n",
    "\n",
    "    train_data_gen = generator.flow_from_directory(dataset_path, \n",
    "                                                   #color_mode='grayscale', \n",
    "                                                   target_size=(img_size,img_size),\n",
    "                                                   subset='training', \n",
    "                                                   batch_size=batch_size)\n",
    "\n",
    "    test_data_gen = generator.flow_from_directory(dataset_path, \n",
    "                                                  #color_mode='grayscale', \n",
    "                                                  target_size=(img_size,img_size), \n",
    "                                                  subset='validation', \n",
    "                                                  batch_size=1,\n",
    "                                                  shuffle=False)\n",
    "\n",
    "    model = None\n",
    "    model_ckp = os.path.basename(dataset_path) + '_resnet_ckp_' + str(i) + '.hdf5'\n",
    "\n",
    "    checkpointer = callbacks.ModelCheckpoint(filepath=model_ckp, verbose=1, save_best_only=True)\n",
    "    reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.001)\n",
    "    tensorboard = callbacks.TensorBoard()\n",
    "    progbar = callbacks.ProgbarLogger()\n",
    "    earlystop = callbacks.EarlyStopping(patience=8)\n",
    "    csv_logger = callbacks.CSVLogger(os.path.basename(dataset_path) + '_resnet_' + str(i) + '.csv')\n",
    "\n",
    "    # if os.path.exists(model_ckp):\n",
    "    #     model = models.load_model(model_ckp)\n",
    "    # else:\n",
    "    model = _resnet(train_data_gen.num_classes, freezed=True)\n",
    "    model.compile(optimizer=optimizers.Adam(lr=0.01), \n",
    "                  loss=losses.categorical_crossentropy, \n",
    "                  metrics=[metrics.categorical_accuracy])\n",
    "\n",
    "#     model.summary()\n",
    "\n",
    "    hist = model.fit_generator(train_data_gen, epochs=50, validation_data=test_data_gen, workers=8, verbose=0,\n",
    "                               callbacks=[checkpointer, csv_logger])\n",
    "\n",
    "\n",
    "    prob = model.predict_generator(test_data_gen, verbose=1)\n",
    "    y_pred = np.argmax(prob, axis=1)\n",
    "    y_true = test_data_gen.classes\n",
    "\n",
    "    #     print(classification_report(y_true, y_pred))\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    np.savetxt(os.path.basename(dataset_path) + '_resnet_confusion_matrix_' + str(i) + '.csv',\n",
    "               confusion_matrix(y_true, y_pred).astype(int), delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No such layer: #layer-name#",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-9f9dc2b6209e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'#layer-name#'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/Keras-2.1.4-py3.6.egg/keras/engine/topology.py\u001b[0m in \u001b[0;36mget_layer\u001b[0;34m(self, name, index)\u001b[0m\n\u001b[1;32m   1889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No such layer: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No such layer: #layer-name#"
     ]
    }
   ],
   "source": [
    "\n",
    "model_features = models.Model(inputs=model.input, outputs=model.get_layer('#layer-name#').output)\n",
    "\n",
    "features = model_features.predict_generator(test_data_gen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['birads5', 'birads3', 'birads4', 'birads2', 'birads1']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path = '/home/daniel/Downloads/CBMS/exp5-1'\n",
    "\n",
    "for i in os.listdir(path):\n",
    "    print()\n",
    "    \n",
    "print(os.listdir('/home/daniel/Downloads/CBMS/exp5-1'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
